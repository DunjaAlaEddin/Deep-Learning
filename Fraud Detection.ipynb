{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5088ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored as cl\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f91823ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
      "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
      "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
      "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
      "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
      "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
      "\n",
      "        V25       V26       V27       V28  Amount  Class  \n",
      "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/dunjaalaeddin/Downloads/creditcard.csv')\n",
    "df.drop('Time', axis = 1, inplace = True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac0de33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCASE COUNT\u001b[0m\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n",
      "Total number of cases: 284807\n",
      "Number of Non-fraud cases: 284315\n",
      "Number of Fraud cases: 492\n",
      "Percentage of fraud cases: 0.17\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cases = len(df)\n",
    "nonfraud_count = len(df[df.Class == 0])\n",
    "fraud_count = len(df[df.Class == 1])\n",
    "fraud_percentage = round(fraud_count/cases*100, 2)\n",
    "\n",
    "print(cl('CASE COUNT', attrs = ['bold']))\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))\n",
    "print('Total number of cases: {}'.format(cases))\n",
    "print('Number of Non-fraud cases: {}'.format(nonfraud_count))\n",
    "print('Number of Fraud cases: {}'.format(fraud_count))\n",
    "print('Percentage of fraud cases: {}'.format(fraud_percentage))\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d19c8477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCASE AMOUNT STATISTICS\u001b[0m\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n",
      "\u001b[1mNON-FRAUD CASE AMOUNT STATS\u001b[0m\n",
      "count    284315.000000\n",
      "mean         88.291022\n",
      "std         250.105092\n",
      "min           0.000000\n",
      "25%           5.650000\n",
      "50%          22.000000\n",
      "75%          77.050000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n",
      "\u001b[1mFRAUD CASE AMOUNT STATS\u001b[0m\n",
      "count     492.000000\n",
      "mean      122.211321\n",
      "std       256.683288\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         9.250000\n",
      "75%       105.890000\n",
      "max      2125.870000\n",
      "Name: Amount, dtype: float64\n",
      "\u001b[1m--------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(cl('CASE AMOUNT STATISTICS', attrs = ['bold']))\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))\n",
    "print(cl('NON-FRAUD CASE AMOUNT STATS', attrs = ['bold']))\n",
    "print(nonfraud_cases.Amount.describe())\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))\n",
    "print(cl('FRAUD CASE AMOUNT STATS', attrs = ['bold']))\n",
    "print(fraud_cases.Amount.describe())\n",
    "print(cl('--------------------------------------------', attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d41baa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.244964\n",
      "1   -0.342475\n",
      "2    1.160686\n",
      "3    0.140534\n",
      "4   -0.073403\n",
      "5   -0.338556\n",
      "6   -0.333279\n",
      "7   -0.190107\n",
      "8    0.019392\n",
      "9   -0.338516\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "amount = df['Amount'].values\n",
    "\n",
    "df['Amount'] = sc.fit_transform(amount.reshape(-1, 1))\n",
    "\n",
    "print(df['Amount'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3444dbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mX_train samples : \u001b[0m [[ 1.95504092 -0.38078271 -0.31501285  0.33015545 -0.50937425 -0.08619745\n",
      "  -0.62797791  0.03599372  1.0545603  -0.03044134  0.62499577  1.69149569\n",
      "   1.2557904  -0.25326646 -0.33169498  0.30725235 -0.93084369  0.65166579\n",
      "   0.16798664 -0.12538999  0.23819742  0.96830494  0.05320802 -0.27860151\n",
      "  -0.0449993  -0.21678034  0.04516825 -0.04714479  9.99      ]]\n",
      "\u001b[1mX_test samples : \u001b[0m [[-1.65265066e+01  8.58497180e+00 -1.86498532e+01  9.50559352e+00\n",
      "  -1.37938185e+01 -2.83240430e+00 -1.67016943e+01  7.51734390e+00\n",
      "  -8.50705864e+00 -1.41101844e+01  5.29923635e+00 -1.08340065e+01\n",
      "   1.67112025e+00 -9.37385858e+00  3.60805642e-01 -9.89924654e+00\n",
      "  -1.92362924e+01 -8.39855199e+00  3.10173537e+00 -1.51492344e+00\n",
      "   1.19073869e+00 -1.12767001e+00 -2.35857877e+00  6.73461329e-01\n",
      "  -1.41369967e+00 -4.62762361e-01 -2.01857525e+00 -1.04280417e+00\n",
      "   3.64190000e+02]]\n",
      "\u001b[1my_train samples : \u001b[0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1my_test samples : \u001b[0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Class', axis = 1).values\n",
    "y = df['Class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42\n",
    "                                                    )\n",
    "\n",
    "print(cl('X_train samples : ', attrs = ['bold']), X_train[:1])\n",
    "print(cl('X_test samples : ', attrs = ['bold']), X_test[0:1])\n",
    "print(cl('y_train samples : ', attrs = ['bold']), y_train[0:20])\n",
    "print(cl('y_test samples : ', attrs = ['bold']), y_test[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bf8c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "decision_tree.fit(X_train, y_train)\n",
    "tree_yhat = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cc8501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5, n_jobs = -1)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_yhat = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd25c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunjaalaeddin/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "logistic_regression_yhat = logistic_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "768a7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_yhat = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfff73ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(max_depth = 4)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest_yhat = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fddd37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth = 4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cl('ACCURACY SCORE', attrs = ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
    "print(cl('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, tree_yhat)), attrs = ['bold']))\n",
    "print(cl('Accuracy score of the KNN model is {}'.format(accuracy_score(y_test, knn_yhat)), attrs = ['bold'], color = 'green'))\n",
    "print(cl('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)), attrs = ['bold'], color = 'red'))\n",
    "print(cl('Accuracy score of the SVM model is {}'.format(accuracy_score(y_test, svm_yhat)), attrs = ['bold']))\n",
    "print(cl('Accuracy score of the Random Forest Tree model is {}'.format(accuracy_score(y_test, rf_yhat)), attrs = ['bold']))\n",
    "print(cl('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)), attrs = ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5492b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cl('F1 SCORE', attrs = ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
    "print(cl('Decision Tree: {}'.format(f1_score(y_test, tree_yhat)), attrs = ['bold']))\n",
    "print(cl('KNN: {}'.format(f1_score(y_test, knn_yhat)), attrs = ['bold'], color = 'green'))\n",
    "print(cl('Logistic Regression: {}'.format(f1_score(y_test, lr_yhat)), attrs = ['bold'], color = 'red'))\n",
    "print(cl('SVM: {}'.format(f1_score(y_test, svm_yhat)), attrs = ['bold']))\n",
    "print(cl('Random Forest Tree: {}'.format(f1_score(y_test, rf_yhat)), attrs = ['bold']))\n",
    "print(cl('XGBoost: {}'.format(f1_score(y_test, xgb_yhat)), attrs = ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c937b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Confusion Matrix\n",
    "\n",
    "# defining the plot function\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title, normalize = False, cmap = plt.cm.Blues):\n",
    "    title = 'Confusion Matrix of {}'.format(title)\n",
    "    if normalize:\n",
    "        cm = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment = 'center',\n",
    "                 color = 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix for the models\n",
    "\n",
    "tree_matrix = confusion_matrix(y_test, tree_yhat, labels = [0, 1]) # Decision Tree\n",
    "knn_matrix = confusion_matrix(y_test, knn_yhat, labels = [0, 1]) # K-Nearest Neighbors\n",
    "lr_matrix = confusion_matrix(y_test, lr_yhat, labels = [0, 1]) # Logistic Regression\n",
    "svm_matrix = confusion_matrix(y_test, svm_yhat, labels = [0, 1]) # Support Vector Machine\n",
    "rf_matrix = confusion_matrix(y_test, rf_yhat, labels = [0, 1]) # Random Forest Tree\n",
    "xgb_matrix = confusion_matrix(y_test, xgb_yhat, labels = [0, 1]) # XGBoost\n",
    "\n",
    "# Plot the confusion matrix\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6, 6)\n",
    "\n",
    "# 1. Decision tree\n",
    "\n",
    "tree_cm_plot = plot_confusion_matrix(tree_matrix, \n",
    "                                classes = ['Non-Default(0)','Default(1)'], \n",
    "                                normalize = False, title = 'Decision Tree')\n",
    "plt.savefig('tree_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# 2. K-Nearest Neighbors\n",
    "\n",
    "knn_cm_plot = plot_confusion_matrix(knn_matrix, \n",
    "                                classes = ['Non-Default(0)','Default(1)'], \n",
    "                                normalize = False, title = 'KNN')\n",
    "plt.savefig('knn_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# 3. Logistic regression\n",
    "\n",
    "lr_cm_plot = plot_confusion_matrix(lr_matrix, \n",
    "                                classes = ['Non-Default(0)','Default(1)'], \n",
    "                                normalize = False, title = 'Logistic Regression')\n",
    "plt.savefig('lr_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "\n",
    "svm_cm_plot = plot_confusion_matrix(svm_matrix, \n",
    "                                classes = ['Non-Default(0)','Default(1)'], \n",
    "                                normalize = False, title = 'SVM')\n",
    "plt.savefig('svm_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# 5. Random forest tree\n",
    "\n",
    "rf_cm_plot = plot_confusion_matrix(rf_matrix, \n",
    "                                classes = ['Non-Default(0)','Default(1)'], \n",
    "                                normalize = False, title = 'Random Forest Tree')\n",
    "plt.savefig('rf_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. XGBoost\n",
    "\n",
    "xgb_cm_plot = plot_confusion_matrix(xgb_matrix, \n",
    "                                classes = ['Non-Default(0)','Default(1)'], \n",
    "                                normalize = False, title = 'XGBoost')\n",
    "plt.savefig('xgb_cm_plot.png')\n",
    "plt.show()\n",
    "view raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc4e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
